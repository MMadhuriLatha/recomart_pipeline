{"timestamp":"2026-01-22T05:19:05.436776Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-22T05:19:05.437529Z","level":"info","event":"Filling up the DagBag from /Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-22T05:19:06.937884Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-01-22T05:19:06.972081Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:06.972182Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:06.972685Z","level":"info","event":"Current task name:clean","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:06.972756Z","level":"info","event":"Dag name:recomart_recommendation_pipeline","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:06.973524Z","level":"info","event":"Starting data cleaning...","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:06.981867Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.981871Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:19:06.982727Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [data_cleaner.py:144] - Starting data cleaning. Initial shape: (9910, 4)","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.982723Z","level":"info","event":"Starting data cleaning. Initial shape: (9910, 4)","logger":"data_preparation","filename":"data_cleaner.py","lineno":144}
{"timestamp":"2026-01-22T05:19:06.984747Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.984680Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:19:06.986246Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [data_cleaner.py:79] - Removed 0 duplicate records","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.986246Z","level":"info","event":"Removed 0 duplicate records","logger":"data_preparation","filename":"data_cleaner.py","lineno":79}
{"timestamp":"2026-01-22T05:19:06.987210Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.00s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.987217Z","level":"info","event":"Completed data_preparation in 0.00s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:19:06.989320Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.989322Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:19:06.990773Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.00s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.990764Z","level":"info","event":"Completed data_preparation in 0.00s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:19:06.991965Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [data_cleaner.py:167] - TEST>>>>>>>>>>>>>>>>>>>>>>>> Filtered invalid ratings. Removed 0 rows. Remaining rows: 9910","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.991961Z","level":"info","event":"TEST>>>>>>>>>>>>>>>>>>>>>>>> Filtered invalid ratings. Removed 0 rows. Remaining rows: 9910","logger":"data_preparation","filename":"data_cleaner.py","lineno":167}
{"timestamp":"2026-01-22T05:19:06.994620Z","level":"error","event":"2026-01-22 10:49:06 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:06.994542Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:19:07.001226Z","level":"error","event":"2026-01-22 10:49:07 - data_preparation - INFO - [data_cleaner.py:134] - Extracted temporal features from timestamp","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:07.001224Z","level":"info","event":"Extracted temporal features from timestamp","logger":"data_preparation","filename":"data_cleaner.py","lineno":134}
{"timestamp":"2026-01-22T05:19:07.002258Z","level":"error","event":"2026-01-22 10:49:07 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.01s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:07.002262Z","level":"info","event":"Completed data_preparation in 0.01s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:19:07.002954Z","level":"error","event":"2026-01-22 10:49:07 - data_preparation - INFO - [data_cleaner.py:181] - Cleaning completed. Final shape: (9910, 10)","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:07.002948Z","level":"info","event":"Cleaning completed. Final shape: (9910, 10)","logger":"data_preparation","filename":"data_cleaner.py","lineno":181}
{"timestamp":"2026-01-22T05:19:07.017534Z","level":"error","event":"2026-01-22 10:49:07 - data_preparation - INFO - [data_cleaner.py:184] - Saved cleaned data to: data/processed/interactions_cleaned_20260122_104907.parquet","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:07.017529Z","level":"info","event":"Saved cleaned data to: data/processed/interactions_cleaned_20260122_104907.parquet","logger":"data_preparation","filename":"data_cleaner.py","lineno":184}
{"timestamp":"2026-01-22T05:19:07.018587Z","level":"error","event":"2026-01-22 10:49:07 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.04s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:19:07.018581Z","level":"info","event":"Completed data_preparation in 0.04s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:19:07.023033Z","level":"info","event":"Cleaned data: 9910 records","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:07.023315Z","level":"info","event":"Done. Returned value was: 9910","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-22T05:19:07.023414Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019be41b-064b-78f0-a6e9-ec852c2093c6'), task_id='clean', dag_id='recomart_recommendation_pipeline', run_id='scheduled__2026-01-22T00:00:00+00:00', try_number=2, dag_version_id=UUID('019be403-d3b1-7598-97fa-b6894e3d00a9'), map_index=-1, hostname='apinto-mbp', context_carrier={}, task=<Task(PythonOperator): clean>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2026, 1, 22, 5, 19, 5, 35019, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1357}
{"timestamp":"2026-01-22T05:19:07.032467Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:07.032521Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:19:07.039517Z","level":"info","event":"Task operator:<Task(PythonOperator): clean>","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:50.961766Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-22T05:53:50.962059Z","level":"info","event":"Filling up the DagBag from /Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-22T05:53:52.716081Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-01-22T05:53:52.729376Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.729498Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.729907Z","level":"info","event":"Current task name:clean","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.729967Z","level":"info","event":"Dag name:recomart_recommendation_pipeline","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.730784Z","level":"info","event":"Starting data cleaning...","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.740256Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.740256Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:53:52.741058Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [data_cleaner.py:144] - Starting data cleaning. Initial shape: (9910, 4)","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.741039Z","level":"info","event":"Starting data cleaning. Initial shape: (9910, 4)","logger":"data_preparation","filename":"data_cleaner.py","lineno":144}
{"timestamp":"2026-01-22T05:53:52.743876Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.743884Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:53:52.745599Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [data_cleaner.py:79] - Removed 0 duplicate records","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.745591Z","level":"info","event":"Removed 0 duplicate records","logger":"data_preparation","filename":"data_cleaner.py","lineno":79}
{"timestamp":"2026-01-22T05:53:52.746826Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.00s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.746815Z","level":"info","event":"Completed data_preparation in 0.00s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:53:52.749321Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.749322Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:53:52.750874Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.00s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.750863Z","level":"info","event":"Completed data_preparation in 0.00s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:53:52.752256Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [data_cleaner.py:167] - TEST>>>>>>>>>>>>>>>>>>>>>>>> Filtered invalid ratings. Removed 0 rows. Remaining rows: 9910","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.752254Z","level":"info","event":"TEST>>>>>>>>>>>>>>>>>>>>>>>> Filtered invalid ratings. Removed 0 rows. Remaining rows: 9910","logger":"data_preparation","filename":"data_cleaner.py","lineno":167}
{"timestamp":"2026-01-22T05:53:52.754208Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:58] - Starting data_preparation","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.754203Z","level":"info","event":"Starting data_preparation","logger":"data_preparation","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:53:52.762246Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [data_cleaner.py:134] - Extracted temporal features from timestamp","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.762233Z","level":"info","event":"Extracted temporal features from timestamp","logger":"data_preparation","filename":"data_cleaner.py","lineno":134}
{"timestamp":"2026-01-22T05:53:52.763589Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.01s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.763571Z","level":"info","event":"Completed data_preparation in 0.01s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:53:52.764346Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [data_cleaner.py:181] - Cleaning completed. Final shape: (9910, 10)","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.764343Z","level":"info","event":"Cleaning completed. Final shape: (9910, 10)","logger":"data_preparation","filename":"data_cleaner.py","lineno":181}
{"timestamp":"2026-01-22T05:53:52.802823Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [data_cleaner.py:184] - Saved cleaned data to: data/processed/interactions_cleaned_20260122_112352.parquet","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.802816Z","level":"info","event":"Saved cleaned data to: data/processed/interactions_cleaned_20260122_112352.parquet","logger":"data_preparation","filename":"data_cleaner.py","lineno":184}
{"timestamp":"2026-01-22T05:53:52.804165Z","level":"error","event":"2026-01-22 11:23:52 - data_preparation - INFO - [logger.py:65] - Completed data_preparation in 0.06s","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:53:52.804164Z","level":"info","event":"Completed data_preparation in 0.06s","logger":"data_preparation","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T05:53:52.809623Z","level":"info","event":"Cleaned data: 9910 records","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.809981Z","level":"info","event":"Done. Returned value was: 9910","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-22T05:53:52.810084Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019be444-2439-7fdc-92e6-7a6b88065327'), task_id='clean', dag_id='recomart_recommendation_pipeline', run_id='scheduled__2026-01-22T00:00:00+00:00', try_number=2, dag_version_id=UUID('019be403-d3b1-7598-97fa-b6894e3d00a9'), map_index=-1, hostname='apinto-mbp', context_carrier={}, task=<Task(PythonOperator): clean>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2026, 1, 22, 5, 53, 50, 448304, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1357}
{"timestamp":"2026-01-22T05:53:52.818666Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.818756Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:53:52.819303Z","level":"info","event":"Task operator:<Task(PythonOperator): clean>","logger":"task.stdout"}
{"timestamp":"2026-01-22T07:13:05.050747Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
