{"timestamp":"2026-01-22T05:54:32.238324Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-22T05:54:32.238623Z","level":"info","event":"Filling up the DagBag from /Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-22T05:54:33.790431Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-01-22T05:54:33.803534Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:54:33.803607Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:54:33.804055Z","level":"info","event":"Current task name:train","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:54:33.804113Z","level":"info","event":"Dag name:recomart_recommendation_pipeline","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:54:33.805034Z","level":"info","event":"Starting model training...","logger":"task.stdout"}
{"timestamp":"2026-01-22T05:54:34.179061Z","level":"error","event":"2026-01-22 11:24:34 - model_training - INFO - [logger.py:58] - Starting model_training","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:54:34.179041Z","level":"info","event":"Starting model_training","logger":"model_training","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:54:34.179850Z","level":"error","event":"2026-01-22 11:24:34 - model_training - INFO - [recommender.py:241] - Starting training pipeline for collaborative model","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:54:34.179844Z","level":"info","event":"Starting training pipeline for collaborative model","logger":"model_training","filename":"recommender.py","lineno":241}
{"timestamp":"2026-01-22T05:54:34.183244Z","level":"error","event":"2026-01-22 11:24:34 - model_training - INFO - [recommender.py:254] - Train size: 7928, Test size: 1982","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:54:34.183244Z","level":"info","event":"Train size: 7928, Test size: 1982","logger":"model_training","filename":"recommender.py","lineno":254}
{"timestamp":"2026-01-22T05:54:34.345158Z","level":"error","event":"2026-01-22 11:24:34 - model_training - INFO - [logger.py:58] - Starting model_training","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:54:34.345170Z","level":"info","event":"Starting model_training","logger":"model_training","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T05:54:34.346034Z","level":"error","event":"2026-01-22 11:24:34 - model_training - INFO - [recommender.py:51] - Starting model training","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:54:34.346028Z","level":"info","event":"Starting model training","logger":"model_training","filename":"recommender.py","lineno":51}
{"timestamp":"2026-01-22T05:54:34.355770Z","level":"error","event":"2026-01-22 11:24:34 - model_training - INFO - [recommender.py:61] - Matrix shape: (1000, 500)","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:54:34.355766Z","level":"info","event":"Matrix shape: (1000, 500)","logger":"model_training","filename":"recommender.py","lineno":61}
{"timestamp":"2026-01-22T05:54:34.356412Z","level":"error","event":"2026-01-22 11:24:34 - model_training - INFO - [recommender.py:69] - Performing SVD with 50 factors","logger":"task.stderr"}
{"timestamp":"2026-01-22T05:54:34.356404Z","level":"info","event":"Performing SVD with 50 factors","logger":"model_training","filename":"recommender.py","lineno":69}
{"timestamp":"2026-01-22T06:05:15.688088Z","level":"error","event":"Server indicated the task shouldn't be running anymore. Terminating process","detail":{"detail":{"reason":"not_found","message":"Task Instance not found"}},"logger":"task"}
{"timestamp":"2026-01-22T06:05:20.722396Z","level":"error","event":"Task killed!","logger":"task"}
{"timestamp":"2026-01-22T06:41:58.149148Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-22T06:41:58.149487Z","level":"info","event":"Filling up the DagBag from /Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-22T06:41:59.648526Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-01-22T06:41:59.664404Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:41:59.664482Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:41:59.664925Z","level":"info","event":"Current task name:train","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:41:59.664970Z","level":"info","event":"Dag name:recomart_recommendation_pipeline","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:41:59.665696Z","level":"info","event":"Starting model training...","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:41:59.849289Z","level":"error","event":"2026/01/22 12:11:59 INFO mlflow.store.db.utils: Creating initial MLflow database tables...","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.850116Z","level":"error","event":"2026/01/22 12:11:59 INFO mlflow.store.db.utils: Updating database tables","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.853625Z","level":"error","event":"2026/01/22 12:11:59 INFO alembic.runtime.migration: Context impl SQLiteImpl.","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.854129Z","level":"error","event":"2026/01/22 12:11:59 INFO alembic.runtime.migration: Will assume non-transactional DDL.","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.879108Z","level":"error","event":"2026/01/22 12:11:59 INFO alembic.runtime.migration: Context impl SQLiteImpl.","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.879421Z","level":"error","event":"2026/01/22 12:11:59 INFO alembic.runtime.migration: Will assume non-transactional DDL.","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.887226Z","level":"error","event":"2026-01-22 12:11:59 - model_training - INFO - [logger.py:58] - Starting model_training","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.887226Z","level":"info","event":"Starting model_training","logger":"model_training","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T06:41:59.887942Z","level":"error","event":"2026-01-22 12:11:59 - model_training - INFO - [recommender.py:275] - Starting training pipeline for collaborative model","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.887938Z","level":"info","event":"Starting training pipeline for collaborative model","logger":"model_training","filename":"recommender.py","lineno":275}
{"timestamp":"2026-01-22T06:41:59.889987Z","level":"error","event":"2026-01-22 12:11:59 - model_training - INFO - [recommender.py:288] - Train size: 7928, Test size: 1982","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:41:59.889987Z","level":"info","event":"Train size: 7928, Test size: 1982","logger":"model_training","filename":"recommender.py","lineno":288}
{"timestamp":"2026-01-22T06:42:00.266496Z","level":"error","event":"2026-01-22 12:12:00 - model_training - INFO - [recommender.py:60] - Starting model training","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.266517Z","level":"info","event":"Starting model training","logger":"model_training","filename":"recommender.py","lineno":60}
{"timestamp":"2026-01-22T06:42:00.274264Z","level":"error","event":"2026-01-22 12:12:00 - model_training - INFO - [recommender.py:79] - Matrix shape: (500, 300)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.274252Z","level":"info","event":"Matrix shape: (500, 300)","logger":"model_training","filename":"recommender.py","lineno":79}
{"timestamp":"2026-01-22T06:42:00.275010Z","level":"error","event":"2026-01-22 12:12:00 - model_training - INFO - [recommender.py:87] - Performing SVD with 50 factors","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.275011Z","level":"info","event":"Performing SVD with 50 factors","logger":"model_training","filename":"recommender.py","lineno":87}
{"timestamp":"2026-01-22T06:42:00.275700Z","level":"error","event":"2026-01-22 12:12:00 - model_training - INFO - [recommender.py:91] - Starting TruncatedSVD computation","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.275696Z","level":"info","event":"Starting TruncatedSVD computation","logger":"model_training","filename":"recommender.py","lineno":91}
{"timestamp":"2026-01-22T06:42:00.282474Z","level":"error","event":"2026-01-22 12:12:00 - model_training - INFO - [recommender.py:105] - Finished TruncatedSVD computation","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.282475Z","level":"info","event":"Finished TruncatedSVD computation","logger":"model_training","filename":"recommender.py","lineno":105}
{"timestamp":"2026-01-22T06:42:00.283426Z","level":"error","event":"2026-01-22 12:12:00 - model_training - INFO - [recommender.py:106] - Model training completed","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.283421Z","level":"info","event":"Model training completed","logger":"model_training","filename":"recommender.py","lineno":106}
{"timestamp":"2026-01-22T06:42:00.284404Z","level":"error","event":"2026-01-22 12:12:00 - model_training - INFO - [recommender.py:191] - Evaluating model","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.284401Z","level":"info","event":"Evaluating model","logger":"model_training","filename":"recommender.py","lineno":191}
{"timestamp":"2026-01-22T06:42:00.290866Z","level":"error","event":"2026-01-22 12:12:00 - model_training - ERROR - [logger.py:67] - Failed model_training after 0.40s","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.290865Z","level":"error","event":"Failed model_training after 0.40s","logger":"model_training","filename":"logger.py","lineno":67}
{"timestamp":"2026-01-22T06:42:00.291853Z","level":"error","event":"2026-01-22 12:12:00 - model_training - ERROR - [logger.py:68] - Error: index 557 is out of bounds for axis 0 with size 500","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:42:00.291868Z","level":"error","event":"Error: index 557 is out of bounds for axis 0 with size 500","logger":"model_training","filename":"logger.py","lineno":68}
{"timestamp":"2026-01-22T06:42:00.292045Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":999,"error_detail":[{"exc_type":"IndexError","exc_value":"index 557 is out of bounds for axis 0 with size 500","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/venv/lib/python3.13/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":925,"name":"run"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/venv/lib/python3.13/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1312,"name":"_execute_task"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/venv/lib/python3.13/site-packages/airflow/sdk/bases/operator.py","lineno":416,"name":"wrapper"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/venv/lib/python3.13/site-packages/airflow/providers/standard/operators/python.py","lineno":214,"name":"execute"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/venv/lib/python3.13/site-packages/airflow/providers/standard/operators/python.py","lineno":237,"name":"execute_callable"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/venv/lib/python3.13/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":82,"name":"run"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","lineno":173,"name":"train_model"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/src/models/recommender.py","lineno":305,"name":"train_and_evaluate"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/src/models/recommender.py","lineno":197,"name":"evaluate"},{"filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/src/models/recommender.py","lineno":133,"name":"predict"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-01-22T06:42:00.302086Z","level":"info","event":"Task instance in failure state","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:42:00.302789Z","level":"info","event":"Task start","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:42:00.302844Z","level":"info","event":"Task:<Task(PythonOperator): train>","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:42:00.302870Z","level":"info","event":"Failure caused by index 557 is out of bounds for axis 0 with size 500","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:44:24.017226Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
{"timestamp":"2026-01-22T14:45:01.053317Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
{"timestamp":"2026-01-22T17:43:40.547438Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
{"timestamp":"2026-01-22T17:58:00.854290Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-22T17:58:00.854766Z","level":"info","event":"Filling up the DagBag from /Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-22T17:58:02.586634Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:02.587460Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:02.587633Z","level":"info","event":"Current task name:train","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:02.587689Z","level":"info","event":"Dag name:recomart_recommendation_pipeline","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:02.588626Z","level":"info","event":"Starting model training...","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:03.023533Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [logger.py:58] - Starting model_training","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.023483Z","level":"info","event":"Starting model_training","logger":"model_training","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T17:58:03.024483Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:241] - Starting training pipeline for collaborative model","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.024474Z","level":"info","event":"Starting training pipeline for collaborative model","logger":"model_training","filename":"recommender.py","lineno":241}
{"timestamp":"2026-01-22T17:58:03.029709Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:254] - Train size: 7928, Test size: 1982","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.029706Z","level":"info","event":"Train size: 7928, Test size: 1982","logger":"model_training","filename":"recommender.py","lineno":254}
{"timestamp":"2026-01-22T17:58:03.212662Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [logger.py:58] - Starting model_training","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.212680Z","level":"info","event":"Starting model_training","logger":"model_training","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T17:58:03.213434Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:51] - Starting model training","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.213428Z","level":"info","event":"Starting model training","logger":"model_training","filename":"recommender.py","lineno":51}
{"timestamp":"2026-01-22T17:58:03.229254Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:61] - Matrix shape: (1000, 500)","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.229217Z","level":"info","event":"Matrix shape: (1000, 500)","logger":"model_training","filename":"recommender.py","lineno":61}
{"timestamp":"2026-01-22T17:58:03.230047Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:69] - Performing SVD with 20 factors","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.230037Z","level":"info","event":"Performing SVD with 20 factors","logger":"model_training","filename":"recommender.py","lineno":69}
{"timestamp":"2026-01-22T17:58:03.256971Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:77] - Model training completed","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.256954Z","level":"info","event":"Model training completed","logger":"model_training","filename":"recommender.py","lineno":77}
{"timestamp":"2026-01-22T17:58:03.258262Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [logger.py:65] - Completed model_training in 0.05s","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.258255Z","level":"info","event":"Completed model_training in 0.05s","logger":"model_training","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T17:58:03.260861Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [logger.py:58] - Starting model_training","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.260855Z","level":"info","event":"Starting model_training","logger":"model_training","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T17:58:03.261753Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:158] - Evaluating model","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.261748Z","level":"info","event":"Evaluating model","logger":"model_training","filename":"recommender.py","lineno":158}
{"timestamp":"2026-01-22T17:58:03.298416Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:177] - RMSE: 2.4047","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.298408Z","level":"info","event":"RMSE: 2.4047","logger":"model_training","filename":"recommender.py","lineno":177}
{"timestamp":"2026-01-22T17:58:03.299401Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [recommender.py:178] - MAE: 1.9430","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.299395Z","level":"info","event":"MAE: 1.9430","logger":"model_training","filename":"recommender.py","lineno":178}
{"timestamp":"2026-01-22T17:58:03.300907Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [logger.py:65] - Completed model_training in 0.04s","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.300903Z","level":"info","event":"Completed model_training in 0.04s","logger":"model_training","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T17:58:03.381749Z","level":"info","event":"üèÉ View run wise-bee-247 at: http://127.0.0.1:5000/#/experiments/1/runs/59b64126ca65433a8d1df107d5107dd7","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:03.381829Z","level":"info","event":"üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:03.386342Z","level":"error","event":"2026-01-22 23:28:03 - model_training - INFO - [logger.py:65] - Completed model_training in 0.36s","logger":"task.stderr"}
{"timestamp":"2026-01-22T17:58:03.386342Z","level":"info","event":"Completed model_training in 0.36s","logger":"model_training","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T17:58:03.397709Z","level":"info","event":"Model trained - RMSE: 2.4047","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:03.397765Z","level":"info","event":"Model trained - MAE: 1.9430","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:03.397940Z","level":"info","event":"Done. Returned value was: {'rmse': 2.404691848444154, 'mae': 1.942986881937437, 'n_predictions': 1982}","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-22T17:58:03.398153Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019be6d6-8e8f-7a4e-a331-adcc82d91e48'), task_id='train', dag_id='recomart_recommendation_pipeline', run_id='scheduled__2026-01-22T00:00:00+00:00', try_number=2, dag_version_id=UUID('019be483-4b20-7641-8635-67f364380c0a'), map_index=-1, hostname='apinto-mbp', context_carrier={}, task=<Task(PythonOperator): train>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=2, start_date=datetime.datetime(2026, 1, 22, 17, 58, 0, 295077, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1357}
{"timestamp":"2026-01-22T17:58:03.407722Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:03.407799Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-22T17:58:03.408593Z","level":"info","event":"Task operator:<Task(PythonOperator): train>","logger":"task.stdout"}
