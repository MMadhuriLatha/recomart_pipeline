{"timestamp":"2026-01-22T05:08:56.079583Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
{"timestamp":"2026-01-22T05:41:11.863635Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
{"timestamp":"2026-01-22T06:43:28.390479Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-22T06:43:28.390785Z","level":"info","event":"Filling up the DagBag from /Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-22T06:43:30.204552Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-01-22T06:43:30.213150Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.213239Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.213871Z","level":"info","event":"Current task name:ingest_api","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.213953Z","level":"info","event":"Dag name:recomart_recommendation_pipeline","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.214733Z","level":"info","event":"Starting API data ingestion...","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.217589Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [logger.py:58] - Starting api_ingestion","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.217677Z","level":"info","event":"Starting api_ingestion","logger":"api_ingestion","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T06:43:30.220495Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [logger.py:58] - Starting api_ingestion","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.220484Z","level":"info","event":"Starting api_ingestion","logger":"api_ingestion","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T06:43:30.221493Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [api_ingestion.py:38] - Fetching data from https://fakestoreapi.com/products (attempt 1)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.221494Z","level":"info","event":"Fetching data from https://fakestoreapi.com/products (attempt 1)","logger":"api_ingestion","filename":"api_ingestion.py","lineno":38}
{"timestamp":"2026-01-22T06:43:30.818477Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [api_ingestion.py:51] - Response status code: 200","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.818457Z","level":"info","event":"Response status code: 200","logger":"api_ingestion","filename":"api_ingestion.py","lineno":51}
{"timestamp":"2026-01-22T06:43:30.819208Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [api_ingestion.py:69] - Successfully fetched 20 records","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.819207Z","level":"info","event":"Successfully fetched 20 records","logger":"api_ingestion","filename":"api_ingestion.py","lineno":69}
{"timestamp":"2026-01-22T06:43:30.820204Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [logger.py:65] - Completed api_ingestion in 0.60s","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.820203Z","level":"info","event":"Completed api_ingestion in 0.60s","logger":"api_ingestion","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T06:43:30.822688Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [api_ingestion.py:125] - Converted to DataFrame: (20, 7)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.822681Z","level":"info","event":"Converted to DataFrame: (20, 7)","logger":"api_ingestion","filename":"api_ingestion.py","lineno":125}
{"timestamp":"2026-01-22T06:43:30.823376Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [api_ingestion.py:126] - Columns: ['id', 'title', 'price', 'description', 'category', 'image', 'rating']","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.823374Z","level":"info","event":"Columns: ['id', 'title', 'price', 'description', 'category', 'image', 'rating']","logger":"api_ingestion","filename":"api_ingestion.py","lineno":126}
{"timestamp":"2026-01-22T06:43:30.827267Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [api_ingestion.py:135] - Saved API data to: data/raw/product_api/2026/01/22/catalog/catalog_20260122_121330.json","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.827269Z","level":"info","event":"Saved API data to: data/raw/product_api/2026/01/22/catalog/catalog_20260122_121330.json","logger":"api_ingestion","filename":"api_ingestion.py","lineno":135}
{"timestamp":"2026-01-22T06:43:30.828828Z","level":"error","event":"2026-01-22 12:13:30 - api_ingestion - INFO - [logger.py:65] - Completed api_ingestion in 0.61s","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:43:30.828827Z","level":"info","event":"Completed api_ingestion in 0.61s","logger":"api_ingestion","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T06:43:30.837800Z","level":"info","event":"Ingested 20 products","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.837845Z","level":"info","event":"Done. Returned value was: data/raw/product_api/2026/01/22/catalog/catalog_20260122_121330.json","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-22T06:43:30.837942Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019be471-931f-7974-a4bc-d98ffc28398c'), task_id='ingest_api', dag_id='recomart_recommendation_pipeline', run_id='scheduled__2026-01-22T00:00:00+00:00', try_number=2, dag_version_id=UUID('019be463-76a8-72eb-8a68-4289b61bd85f'), map_index=-1, hostname='apinto-mbp', context_carrier={}, task=<Task(PythonOperator): ingest_api>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=3, start_date=datetime.datetime(2026, 1, 22, 6, 43, 27, 935877, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1357}
{"timestamp":"2026-01-22T06:43:30.845091Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.845135Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:43:30.845800Z","level":"info","event":"Task operator:<Task(PythonOperator): ingest_api>","logger":"task.stdout"}
