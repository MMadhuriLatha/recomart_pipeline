{"timestamp":"2026-01-22T05:19:07.323064Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
{"timestamp":"2026-01-22T05:47:56.559127Z","level":"critical","event":"\n******************************************* Received SIGSEGV *******************************************\nSIGSEGV (Segmentation Violation) signal indicates Segmentation Fault error which refers to\nan attempt by a program/library to write or read outside its allocated memory.\n\nIn Python environment usually this signal refers to libraries which use low level C API.\nMake sure that you use right libraries/Docker Images\nfor your architecture (Intel/ARM) and/or Operational System (Linux/macOS).\n\nSuggested way to debug\n======================\n  - Set environment variable 'PYTHONFAULTHANDLER' to 'true'.\n  - Start airflow services.\n  - Restart failed airflow task.\n  - Check 'scheduler' and 'worker' services logs for additional traceback\n    which might contain information about module/library where actual error happen.\n\nKnown Issues\n============\n\nNote: Only Linux-based distros supported as \"Production\" execution environment for Airflow.\n\nmacOS\n-----\n 1. Due to limitations in Apple's libraries not every process might 'fork' safe.\n    One of the general error is unable to query the macOS system configuration for network proxies.\n    If your are not using a proxy you could disable it by set environment variable 'no_proxy' to '*'.\n    See: https://github.com/python/cpython/issues/58037 and https://bugs.python.org/issue30385#msg293958\n********************************************************************************************************","logger":"task"}
{"timestamp":"2026-01-22T06:19:18.628789Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-01-22T06:19:18.629062Z","level":"info","event":"Filling up the DagBag from /Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-01-22T06:19:20.343878Z","level":"warning","event":"The `airflow.operators.python.PythonOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.python.PythonOperator'`.","category":"DeprecatedImportWarning","filename":"/Users/apinto/Documents/BITS WILP/Sem2/Assignment/recomart_pipeline/airflow/dags/airflow_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-01-22T06:19:20.360668Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.360758Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.361061Z","level":"info","event":"Current task name:engineer_features","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.361092Z","level":"info","event":"Dag name:recomart_recommendation_pipeline","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.362047Z","level":"info","event":"Starting feature engineering...","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.463428Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [logger.py:58] - Starting feature_engineering","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.463403Z","level":"info","event":"Starting feature_engineering","logger":"feature_engineering","filename":"logger.py","lineno":58}
{"timestamp":"2026-01-22T06:19:20.464471Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:204] - Starting complete feature engineering pipeline","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.464458Z","level":"info","event":"Starting complete feature engineering pipeline","logger":"feature_engineering","filename":"feature_engineer.py","lineno":204}
{"timestamp":"2026-01-22T06:19:20.465461Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:30] - Creating user features","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.465435Z","level":"info","event":"Creating user features","logger":"feature_engineering","filename":"feature_engineer.py","lineno":30}
{"timestamp":"2026-01-22T06:19:20.483325Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:66] - Created 11 user features for 1000 users","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.483300Z","level":"info","event":"Created 11 user features for 1000 users","logger":"feature_engineering","filename":"feature_engineer.py","lineno":66}
{"timestamp":"2026-01-22T06:19:20.484295Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:208] - User features created: (1000, 11)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.484284Z","level":"info","event":"User features created: (1000, 11)","logger":"feature_engineering","filename":"feature_engineer.py","lineno":208}
{"timestamp":"2026-01-22T06:19:20.485462Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:81] - Creating item features","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.485455Z","level":"info","event":"Creating item features","logger":"feature_engineering","filename":"feature_engineer.py","lineno":81}
{"timestamp":"2026-01-22T06:19:20.489075Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:116] - Created 8 item features for 500 items","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.489084Z","level":"info","event":"Created 8 item features for 500 items","logger":"feature_engineering","filename":"feature_engineer.py","lineno":116}
{"timestamp":"2026-01-22T06:19:20.489850Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:212] - Item features created: (500, 8)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.489838Z","level":"info","event":"Item features created: (500, 8)","logger":"feature_engineering","filename":"feature_engineer.py","lineno":212}
{"timestamp":"2026-01-22T06:19:20.490541Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:127] - Creating interaction features","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.490536Z","level":"info","event":"Creating interaction features","logger":"feature_engineering","filename":"feature_engineer.py","lineno":127}
{"timestamp":"2026-01-22T06:19:20.499999Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:138] - Created interaction features. Total columns: 30","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.499999Z","level":"info","event":"Created interaction features. Total columns: 30","logger":"feature_engineering","filename":"feature_engineer.py","lineno":138}
{"timestamp":"2026-01-22T06:19:20.501002Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:221] - Interaction features created: (9910, 30)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.500986Z","level":"info","event":"Interaction features created: (9910, 30)","logger":"feature_engineering","filename":"feature_engineer.py","lineno":221}
{"timestamp":"2026-01-22T06:19:20.501668Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:172] - Creating temporal features","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.501655Z","level":"info","event":"Creating temporal features","logger":"feature_engineering","filename":"feature_engineer.py","lineno":172}
{"timestamp":"2026-01-22T06:19:20.728552Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:191] - Temporal features created","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.728584Z","level":"info","event":"Temporal features created","logger":"feature_engineering","filename":"feature_engineer.py","lineno":191}
{"timestamp":"2026-01-22T06:19:20.731511Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:225] - Temporal features added: (9910, 33)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.731512Z","level":"info","event":"Temporal features added: (9910, 33)","logger":"feature_engineering","filename":"feature_engineer.py","lineno":225}
{"timestamp":"2026-01-22T06:19:20.732293Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:147] - Creating similarity features","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.732293Z","level":"info","event":"Creating similarity features","logger":"feature_engineering","filename":"feature_engineer.py","lineno":147}
{"timestamp":"2026-01-22T06:19:20.755829Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:165] - Computed similarity matrix: (500, 500)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.755751Z","level":"info","event":"Computed similarity matrix: (500, 500)","logger":"feature_engineering","filename":"feature_engineer.py","lineno":165}
{"timestamp":"2026-01-22T06:19:20.758036Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:230] - Similarity features created: (500, 500)","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.758034Z","level":"info","event":"Similarity features created: (500, 500)","logger":"feature_engineering","filename":"feature_engineer.py","lineno":230}
{"timestamp":"2026-01-22T06:19:20.838328Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:237] - All features saved to the feature store","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.838242Z","level":"info","event":"All features saved to the feature store","logger":"feature_engineering","filename":"feature_engineer.py","lineno":237}
{"timestamp":"2026-01-22T06:19:20.839380Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [feature_engineer.py:239] - Feature engineering pipeline completed successfully","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.839372Z","level":"info","event":"Feature engineering pipeline completed successfully","logger":"feature_engineering","filename":"feature_engineer.py","lineno":239}
{"timestamp":"2026-01-22T06:19:20.840638Z","level":"error","event":"2026-01-22 11:49:20 - feature_engineering - INFO - [logger.py:65] - Completed feature_engineering in 0.38s","logger":"task.stderr"}
{"timestamp":"2026-01-22T06:19:20.840617Z","level":"info","event":"Completed feature_engineering in 0.38s","logger":"feature_engineering","filename":"logger.py","lineno":65}
{"timestamp":"2026-01-22T06:19:20.851115Z","level":"info","event":"Created features for 1000 users","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.851200Z","level":"info","event":"Created features for 500 items","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.851828Z","level":"info","event":"Done. Returned value was: True","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator","filename":"python.py","lineno":216}
{"timestamp":"2026-01-22T06:19:20.851970Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019be456-e103-7312-ac4e-82685c91124b'), task_id='engineer_features', dag_id='recomart_recommendation_pipeline', run_id='scheduled__2026-01-22T00:00:00+00:00', try_number=3, dag_version_id=UUID('019be403-d3b1-7598-97fa-b6894e3d00a9'), map_index=-1, hostname='apinto-mbp', context_carrier={}, task=<Task(PythonOperator): engineer_features>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=2, start_date=datetime.datetime(2026, 1, 22, 6, 19, 17, 986279, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1357}
{"timestamp":"2026-01-22T06:19:20.863526Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.863589Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-01-22T06:19:20.864246Z","level":"info","event":"Task operator:<Task(PythonOperator): engineer_features>","logger":"task.stdout"}
